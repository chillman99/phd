//
// SQL-MR Starter Code Generated by Aster Developer Express
//
package aster2dpeaks;

import java.util.ArrayList;
import java.util.List;

import com.asterdata.ncluster.sqlmr.OutputInfo;
import com.asterdata.ncluster.sqlmr.RowFunction;
import com.asterdata.ncluster.sqlmr.RuntimeContract;
import com.asterdata.ncluster.sqlmr.data.ColumnDefinition;
import com.asterdata.ncluster.sqlmr.data.RowEmitter;
import com.asterdata.ncluster.sqlmr.data.RowIterator;
import com.asterdata.ncluster.sqlmr.data.SqlType;

import phd2dcore.PointWeighted;
import phd2dcore.Pp2dProcess;

public final class PeakPick2D implements RowFunction {

	public PeakPick2D(RuntimeContract contract) {
		//
		// List the columns in the input row
		// these match those in the SQL table
		List<SqlType> expectedInputTypes = new ArrayList<SqlType>();
		expectedInputTypes.add(SqlType.getType("integer"));			//scan
		expectedInputTypes.add(SqlType.getType("integer"));			//mslvl
		expectedInputTypes.add(SqlType.getType("double precision"));//rettime
		expectedInputTypes.add(SqlType.getType("character varying"));//mzarray
		expectedInputTypes.add(SqlType.getType("character varying"));//intensityarray
		
		List<SqlType> actualInputTypes = new ArrayList<SqlType>();

		for (ColumnDefinition d : contract.getInputInfo().getColumns())
			actualInputTypes.add(d.getColumnType());

		List<ColumnDefinition> outputColumns = new ArrayList<ColumnDefinition>();
				
		outputColumns.add(new ColumnDefinition("pkey", SqlType.getType("Integer")));		
		outputColumns.add(new ColumnDefinition("scan", SqlType.getType("Integer")));		
		outputColumns.add(new ColumnDefinition("scanlevel", SqlType.getType("Integer")));
		outputColumns.add(new ColumnDefinition("rt", SqlType.getType("double precision")));
		outputColumns.add(new ColumnDefinition("curveID", SqlType.getType("Integer")));
		outputColumns.add(new ColumnDefinition("wpm", SqlType.getType("double precision")));
		outputColumns.add(new ColumnDefinition("sumi", SqlType.getType("double precision")));
		outputColumns.add(new ColumnDefinition("charge", SqlType.getType("Integer")));
		contract.setOutputInfo(new OutputInfo(outputColumns));
		contract.complete();
	}

	public void operateOnSomeRows(RowIterator inputIterator,
			RowEmitter outputEmitter) {
			
		//each input row corresponds to a single scan
		while (inputIterator.advanceToNextRow()) {		
			String scNumber = new String();
			String scLevel = new String();
			String mzString = new String();
			String intensityString = new String();	
			String RT = "0";
		    
		    //Parse input String from HDFS
		    scNumber = inputIterator.getStringAt(0);
		    scLevel = inputIterator.getStringAt(1);
		    RT = inputIterator.getStringAt(2);
		    mzString = inputIterator.getStringAt(3);
			intensityString  = inputIterator.getStringAt(4);
					
			//Populate outputPoints with the isotopic centroided peaks
			ArrayList<PointWeighted> outputPoints = Pp2dProcess.process(scNumber, scLevel, mzString, intensityString, RT);
			
			if (outputPoints.size()>0) {
				//Write out to HDFS
				for (int i=0; i<outputPoints.size(); i++){
															
					outputEmitter.addInt(outputPoints.get(i).getoutKey());
					outputEmitter.addInt(Integer.parseInt(scNumber));	
					outputEmitter.addInt(Integer.parseInt(scLevel));	
					outputEmitter.addDouble(Double.parseDouble(RT));								
					outputEmitter.addDouble(outputPoints.get(i).getCurveID());
					outputEmitter.addDouble(outputPoints.get(i).getWpm());
					outputEmitter.addDouble(outputPoints.get(i).getSumI());
					outputEmitter.addInt(outputPoints.get(i).getCharge());	
					
					outputEmitter.emitRow();
				
				}
		
			}
	
		}

	}
	
}